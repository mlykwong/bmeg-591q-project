{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2823f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3fd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register():\n",
    "    output_dir = \"../HaN-Seg Registered\"\n",
    "\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath_ct = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_CT.nrrd\"\n",
    "        filepath_mri = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_MR_T1.nrrd\"\n",
    "        ct = sitk.ReadImage(filepath_ct, sitk.sitkFloat32)\n",
    "        mri = sitk.ReadImage(filepath_mri, sitk.sitkFloat32)\n",
    "        \n",
    "        # Registers the MRI image to the CT image\n",
    "        mri_registered = register_helper(ct, mri)\n",
    "\n",
    "        # Saves image to the HaN-Seg Registration Folder\n",
    "        output_path = os.path.join(output_dir, f\"MRI_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(mri_registered, output_path)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Add notation here\n",
    "def register_helper(fixed_image, moving_image):\n",
    "\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        fixed_image,\n",
    "        moving_image,\n",
    "        sitk.Euler3DTransform(),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY,\n",
    "    )\n",
    "\n",
    "    min_value = float(sitk.GetArrayViewFromImage(moving_image).min())\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        initial_transform,\n",
    "        sitk.sitkLinear,\n",
    "        min_value,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "    # Similarity metric settings.\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "    # Optimizer settings.\n",
    "    registration_method.SetOptimizerAsGradientDescent(\n",
    "        learningRate=1.0,\n",
    "        numberOfIterations=100,\n",
    "        convergenceMinimumValue=1e-6,\n",
    "        convergenceWindowSize=10,\n",
    "    )\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "    # Setup for the multi-resolution framework.\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "    final_transform = registration_method.Execute(\n",
    "        sitk.Cast(fixed_image, sitk.sitkFloat32), sitk.Cast(moving_image, sitk.sitkFloat32)\n",
    "    )\n",
    "\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        final_transform,\n",
    "        sitk.sitkLinear,\n",
    "        min_value,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "    return moving_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6c5c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneVolume():\n",
    "    output_dir = \"../HaN-Seg Pruned\"\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath_mri = f\"../HaN-Seg Registered/MRI_Case_{case_num}.nrrd\"\n",
    "        mri = sitk.ReadImage(filepath_mri, sitk.sitkFloat32)\n",
    "        mri = sitk.GetArrayViewFromImage(mri).astype(np.float32)\n",
    "\n",
    "        filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_OAR_Bone_Mandible.seg.nrrd\"\n",
    "        gt = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        gt = sitk.GetArrayViewFromImage(gt).astype(np.float32)\n",
    "\n",
    "        gt_var = np.var(gt, axis = (1, 2))\n",
    "        mask = gt_var > 1e-10\n",
    "        mri = mri[mask]\n",
    "        mri = sitk.GetImageFromArray(mri)\n",
    "        gt = gt[mask]\n",
    "        gt = sitk.GetImageFromArray(gt)\n",
    "\n",
    "        output_path = os.path.join(output_dir, \"MRI\", f\"MRI_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(mri, output_path)\n",
    "\n",
    "        output_path = os.path.join(output_dir, \"GT\", f\"GT_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(gt, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b4d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00b390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruneVolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018566c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 42)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_RESIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_path, mask_path):\n",
    "    mri = sitk.ReadImage(img_path, sitk.sitkFloat32)\n",
    "    gt = sitk.ReadImage(mask_path, sitk.sitkFloat32)\n",
    "\n",
    "    slices = sitk.GetArrayViewFromImage(mri).astype(np.float32)\n",
    "    slices_gt = sitk.GetArrayViewFromImage(gt).astype(np.float32)\n",
    "\n",
    "    slice_arr = np.array(slices)\n",
    "    slices_gt_arr = np.array(slices_gt)\n",
    "\n",
    "    slices_resize = np.expand_dims(slice_arr, axis=-1)\n",
    "    slices_gt_resize = np.expand_dims(slices_gt_arr, axis=-1)\n",
    "\n",
    "    slices_resize = tf.image.resize(slices_resize, (IMAGE_RESIZE, IMAGE_RESIZE))\n",
    "    slices_gt_resize = tf.image.resize(slices_gt_resize, (IMAGE_RESIZE, IMAGE_RESIZE))\n",
    "\n",
    "    return slices_resize, slices_gt_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    output_dir = \"../HaN-Seg Normalized\"\n",
    "    img_sum = 0.0\n",
    "    img_sq_sum = 0.0\n",
    "    total = 0\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath = f\"../HaN-Seg Pruned/MRI_Case_{case_num}.nrrd\"\n",
    "        mri = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        mri = sitk.GetArrayViewFromImage(mri).astype(np.float32)\n",
    "        img_sum += np.sum(mri)\n",
    "        img_sq_sum += np.sum(mri ** 2)\n",
    "        total += mri.size\n",
    "    \n",
    "    train_mean = img_sum/total\n",
    "    train_sd = np.sqrt(img_sq_sum/total - (train_mean**2))\n",
    "\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath = f\"../HaN-Seg Pruned/MRI_Case_{case_num}.nrrd\"\n",
    "        mri = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        mri = sitk.GetArrayViewFromImage(mri).astype(np.float32)\n",
    "    \n",
    "    normalized = (normalized - train_mean) / train_sd\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"MRI_Case_{case_num}.nrrd\")\n",
    "    sitk.WriteImage(normalized, output_path)\n",
    "\n",
    "    return train_mean, train_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = []\n",
    "gt_path = []\n",
    "\n",
    "train_mean, train_sd = normalize()\n",
    "\n",
    "for i in range(1, 43):\n",
    "    case_num = f\"{i:02d}\"\n",
    "    filepath_mri = f\"../HaN-Seg Normalized/MRI_Case_{case_num}.nrrd\"\n",
    "    img_path.append(filepath_mri)\n",
    "    filepath_gt = f\"../HaN-Seg Pruned/GT/GT_Case_{case_num}.nrrd\"\n",
    "    gt_path.append(filepath_gt)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_path, gt_path, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset\n",
    "    .map(\n",
    "    lambda img_path, gt_path : tf.py_function(\n",
    "        func = load_images, \n",
    "        inp = [img_path, gt_path],\n",
    "        Tout = [tf.float32, tf.float32]),\n",
    "        num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "test_dataset = (\n",
    "    test_dataset\n",
    "    .map(\n",
    "    lambda img_path, gt_path : tf.py_function(\n",
    "        func = load_images, \n",
    "        inp = [img_path, gt_path],\n",
    "        Tout = [tf.float32, tf.float32]),\n",
    "        num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A single Encoding step in the Contracting path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (n/2 x n/2) with num_channels feature channels\n",
    "def encode_block(inputs, num_channels):\n",
    "    # Extract num_channels feature channels from image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    skip = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Downsample each channels feature map by a factor of 2\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(skip)\n",
    "\n",
    "    return skip, x\n",
    "\n",
    "## A single Decoding step in the Expanding path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       skip_connection: tensor of corresponding encoding block\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (2nx2n) with num_channels feature channels\n",
    "def decode_block(inputs, skip_connection, num_channels):\n",
    "    # Upsample image by doubling feature space while changing feature channels to num_channels\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_channels, (2,2), strides=2, padding='same')(inputs)\n",
    "\n",
    "    # Concatonate the skip_channel and the upsampled image (doubles the feature channels)\n",
    "    # Might need to resize skip_connection, but should be fine b/c same padding in encoding\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Merge feature channels from the skip_connection and upsampled input image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Metrics\n",
    "# Source: https://medium.com/mastering-data-science/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return (2*tp)/(2*tp + fp + fn)\n",
    "\n",
    "def rand_index(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    return (tp + tn) / (tp + tn + fn + fp)\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_negatives = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    possible_negatives = tf.reduce_sum(tf.cast(1 - y_true, tf.float32))\n",
    "    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(IMAGE_RESIZE, IMAGE_RESIZE, 1))\n",
    "\n",
    "# Do 5 calls of encode_block to end up with a 32x32x512 tensor\n",
    "s1, e1 = encode_block(input, 32)\n",
    "s2, e2 = encode_block(e1, 64)\n",
    "s3, e3 = encode_block(e2, 128)\n",
    "s4, e4 = encode_block(e3, 256)\n",
    "s5, e5 = encode_block(e4, 512)\n",
    "\n",
    "# Bottleneck\n",
    "b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(e5)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(b1)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "\n",
    "# Do 5 calls of decode_block\n",
    "d1 = decode_block(b1, s5, 512)\n",
    "d2 = decode_block(d1, s4, 256)\n",
    "d3 = decode_block(d2, s3, 128)\n",
    "d4 = decode_block(d3, s2, 64)\n",
    "d5 = decode_block(d4, s1, 32)\n",
    "\n",
    "# Play around with activation\n",
    "output = tf.keras.layers.Conv2D(1, 1, padding='same', activation='sigmoid')(d5)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input, outputs=output, name='U-Net')\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss= 'binary_crossentropy',\n",
    "    metrics=['accuracy', dice_coeff, specificity, rand_index, jaccard_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 4\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset,\n",
    "    epochs = EPOCH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Model/u-net_cnn.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
