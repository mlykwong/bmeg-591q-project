{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2823f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3fd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register():\n",
    "    output_dir = \"../HaN-Seg Registered\"\n",
    "\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath_ct = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_CT.nrrd\"\n",
    "        filepath_mri = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_MR_T1.nrrd\"\n",
    "        ct = sitk.ReadImage(filepath_ct, sitk.sitkFloat32)\n",
    "        mri = sitk.ReadImage(filepath_mri, sitk.sitkFloat32)\n",
    "        \n",
    "        # Registers the MRI image to the CT image\n",
    "        mri_registered = register_helper(ct, mri)\n",
    "\n",
    "        # Saves image to the HaN-Seg Registration Folder\n",
    "        output_path = os.path.join(output_dir, f\"MRI_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(mri_registered, output_path)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Add notation here\n",
    "def register_helper(fixed_image, moving_image):\n",
    "\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        fixed_image,\n",
    "        moving_image,\n",
    "        sitk.Euler3DTransform(),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY,\n",
    "    )\n",
    "\n",
    "    min_value = float(sitk.GetArrayViewFromImage(moving_image).min())\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        initial_transform,\n",
    "        sitk.sitkLinear,\n",
    "        min_value,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "    # Similarity metric settings.\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "    # Optimizer settings.\n",
    "    registration_method.SetOptimizerAsGradientDescent(\n",
    "        learningRate=1.0,\n",
    "        numberOfIterations=100,\n",
    "        convergenceMinimumValue=1e-6,\n",
    "        convergenceWindowSize=10,\n",
    "    )\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "    # Setup for the multi-resolution framework.\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "    final_transform = registration_method.Execute(\n",
    "        sitk.Cast(fixed_image, sitk.sitkFloat32), sitk.Cast(moving_image, sitk.sitkFloat32)\n",
    "    )\n",
    "\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        final_transform,\n",
    "        sitk.sitkLinear,\n",
    "        min_value,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "    return moving_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b4d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bd7f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneVolume():\n",
    "    output_dir = \"../HaN-Seg Pruned\"\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath_mri = f\"../HaN-Seg Registered/MRI_Case_{case_num}.nrrd\"\n",
    "        mri = sitk.ReadImage(filepath_mri, sitk.sitkFloat32)\n",
    "        mri = sitk.GetArrayFromImage(mri).astype(np.float32)\n",
    "\n",
    "        filepath_ct = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_CT.nrrd\"\n",
    "        ct = sitk.ReadImage(filepath_ct, sitk.sitkFloat32)\n",
    "        ct = sitk.GetArrayFromImage(ct).astype(np.float32)\n",
    "\n",
    "        filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_OAR_Bone_Mandible.seg.nrrd\"\n",
    "        gt = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        gt = sitk.GetArrayFromImage(gt).astype(np.float32)\n",
    "\n",
    "        gt_var = np.var(gt, axis = (1, 2))\n",
    "        # mask = gt_var > 1e-10\n",
    "        mask = gt_var > 0.0001\n",
    "        mri = mri[mask]\n",
    "        mri = sitk.GetImageFromArray(mri)\n",
    "        ct = ct[mask]\n",
    "        ct = sitk.GetImageFromArray(ct)\n",
    "        gt = gt[mask]\n",
    "        gt = sitk.GetImageFromArray(gt)\n",
    "\n",
    "        output_path = os.path.join(output_dir, \"MRI\", f\"MRI_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(mri, output_path)\n",
    "\n",
    "        output_path = os.path.join(output_dir, \"CT\", f\"CT_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(ct, output_path)\n",
    "\n",
    "        output_path = os.path.join(output_dir, \"GT\", f\"GT_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(gt, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a00b390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruneVolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973413d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histEqual():\n",
    "    output_dir = \"../HaN-Seg Hist Eq\"\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath_mri = f\"../HaN-Seg Pruned/MRI/MRI_Case_{case_num}.nrrd\"\n",
    "        mri = sitk.ReadImage(filepath_mri, sitk.sitkFloat32)\n",
    "        mri_arr = sitk.GetArrayFromImage(mri)\n",
    "        np.linspace(min(mri_arr), max(mri_arr), )\n",
    "\n",
    "        matcher = sitk.HistogramMatchingImageFilter()\n",
    "        matcher.SetNumberOfHistogramLevels(256)\n",
    "        matcher.SetNumberOfMatchPoints(256)\n",
    "        \n",
    "                \n",
    "        mri = matcher.Execute(mri, mri)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"MRI_Case_{case_num}.nrrd\")\n",
    "        sitk.WriteImage(mri, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c509b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histEqual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b264111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 01:\n",
      "  Total slices: 202\n",
      "  Slices with mandible: 43\n",
      "  Mandible pixel ratio: 0.0620%\n",
      "  Variance range: 0.000000 - 0.007484\n",
      "\n",
      "Case 02:\n",
      "  Total slices: 204\n",
      "  Slices with mandible: 43\n",
      "  Mandible pixel ratio: 0.0338%\n",
      "  Variance range: 0.000000 - 0.003865\n",
      "\n",
      "Case 03:\n",
      "  Total slices: 194\n",
      "  Slices with mandible: 42\n",
      "  Mandible pixel ratio: 0.0308%\n",
      "  Variance range: 0.000000 - 0.003596\n",
      "\n",
      "Case 04:\n",
      "  Total slices: 184\n",
      "  Slices with mandible: 44\n",
      "  Mandible pixel ratio: 0.0292%\n",
      "  Variance range: 0.000000 - 0.003253\n",
      "\n",
      "Case 05:\n",
      "  Total slices: 182\n",
      "  Slices with mandible: 34\n",
      "  Mandible pixel ratio: 0.0444%\n",
      "  Variance range: 0.000000 - 0.004947\n",
      "\n",
      "Case 06:\n",
      "  Total slices: 141\n",
      "  Slices with mandible: 29\n",
      "  Mandible pixel ratio: 0.0322%\n",
      "  Variance range: 0.000000 - 0.003588\n",
      "\n",
      "Case 07:\n",
      "  Total slices: 132\n",
      "  Slices with mandible: 24\n",
      "  Mandible pixel ratio: 0.0473%\n",
      "  Variance range: 0.000000 - 0.006957\n",
      "\n",
      "Case 08:\n",
      "  Total slices: 135\n",
      "  Slices with mandible: 28\n",
      "  Mandible pixel ratio: 0.0581%\n",
      "  Variance range: 0.000000 - 0.006443\n",
      "\n",
      "Case 09:\n",
      "  Total slices: 116\n",
      "  Slices with mandible: 22\n",
      "  Mandible pixel ratio: 0.0383%\n",
      "  Variance range: 0.000000 - 0.005221\n",
      "\n",
      "Case 10:\n",
      "  Total slices: 143\n",
      "  Slices with mandible: 31\n",
      "  Mandible pixel ratio: 0.0396%\n",
      "  Variance range: 0.000000 - 0.004247\n",
      "\n",
      "Case 11:\n",
      "  Total slices: 136\n",
      "  Slices with mandible: 26\n",
      "  Mandible pixel ratio: 0.0407%\n",
      "  Variance range: 0.000000 - 0.004838\n",
      "\n",
      "Case 12:\n",
      "  Total slices: 138\n",
      "  Slices with mandible: 25\n",
      "  Mandible pixel ratio: 0.0395%\n",
      "  Variance range: 0.000000 - 0.005683\n",
      "\n",
      "Case 13:\n",
      "  Total slices: 140\n",
      "  Slices with mandible: 29\n",
      "  Mandible pixel ratio: 0.0495%\n",
      "  Variance range: 0.000000 - 0.005573\n",
      "\n",
      "Case 14:\n",
      "  Total slices: 124\n",
      "  Slices with mandible: 25\n",
      "  Mandible pixel ratio: 0.0387%\n",
      "  Variance range: 0.000000 - 0.004242\n",
      "\n",
      "Case 15:\n",
      "  Total slices: 201\n",
      "  Slices with mandible: 30\n",
      "  Mandible pixel ratio: 0.0352%\n",
      "  Variance range: 0.000000 - 0.006191\n",
      "\n",
      "Case 16:\n",
      "  Total slices: 132\n",
      "  Slices with mandible: 34\n",
      "  Mandible pixel ratio: 0.0546%\n",
      "  Variance range: 0.000000 - 0.005734\n",
      "\n",
      "Case 17:\n",
      "  Total slices: 122\n",
      "  Slices with mandible: 31\n",
      "  Mandible pixel ratio: 0.0520%\n",
      "  Variance range: 0.000000 - 0.004953\n",
      "\n",
      "Case 18:\n",
      "  Total slices: 136\n",
      "  Slices with mandible: 28\n",
      "  Mandible pixel ratio: 0.0410%\n",
      "  Variance range: 0.000000 - 0.004385\n",
      "\n",
      "Case 19:\n",
      "  Total slices: 150\n",
      "  Slices with mandible: 30\n",
      "  Mandible pixel ratio: 0.0589%\n",
      "  Variance range: 0.000000 - 0.007210\n",
      "\n",
      "Case 20:\n",
      "  Total slices: 134\n",
      "  Slices with mandible: 27\n",
      "  Mandible pixel ratio: 0.0464%\n",
      "  Variance range: 0.000000 - 0.005578\n",
      "\n",
      "Case 21:\n",
      "  Total slices: 215\n",
      "  Slices with mandible: 38\n",
      "  Mandible pixel ratio: 0.0304%\n",
      "  Variance range: 0.000000 - 0.004053\n",
      "\n",
      "Case 22:\n",
      "  Total slices: 198\n",
      "  Slices with mandible: 41\n",
      "  Mandible pixel ratio: 0.0504%\n",
      "  Variance range: 0.000000 - 0.006665\n",
      "\n",
      "Case 23:\n",
      "  Total slices: 185\n",
      "  Slices with mandible: 45\n",
      "  Mandible pixel ratio: 0.0287%\n",
      "  Variance range: 0.000000 - 0.002808\n",
      "\n",
      "Case 24:\n",
      "  Total slices: 187\n",
      "  Slices with mandible: 33\n",
      "  Mandible pixel ratio: 0.0343%\n",
      "  Variance range: 0.000000 - 0.004393\n",
      "\n",
      "Case 25:\n",
      "  Total slices: 196\n",
      "  Slices with mandible: 50\n",
      "  Mandible pixel ratio: 0.0341%\n",
      "  Variance range: 0.000000 - 0.003699\n",
      "\n",
      "Case 26:\n",
      "  Total slices: 202\n",
      "  Slices with mandible: 50\n",
      "  Mandible pixel ratio: 0.0452%\n",
      "  Variance range: 0.000000 - 0.004635\n",
      "\n",
      "Case 27:\n",
      "  Total slices: 200\n",
      "  Slices with mandible: 36\n",
      "  Mandible pixel ratio: 0.0492%\n",
      "  Variance range: 0.000000 - 0.006911\n",
      "\n",
      "Case 28:\n",
      "  Total slices: 323\n",
      "  Slices with mandible: 49\n",
      "  Mandible pixel ratio: 0.0206%\n",
      "  Variance range: 0.000000 - 0.003501\n",
      "\n",
      "Case 29:\n",
      "  Total slices: 233\n",
      "  Slices with mandible: 42\n",
      "  Mandible pixel ratio: 0.0373%\n",
      "  Variance range: 0.000000 - 0.005639\n",
      "\n",
      "Case 30:\n",
      "  Total slices: 214\n",
      "  Slices with mandible: 36\n",
      "  Mandible pixel ratio: 0.0304%\n",
      "  Variance range: 0.000000 - 0.005272\n",
      "\n",
      "Case 31:\n",
      "  Total slices: 185\n",
      "  Slices with mandible: 38\n",
      "  Mandible pixel ratio: 0.0738%\n",
      "  Variance range: 0.000000 - 0.009146\n",
      "\n",
      "Case 32:\n",
      "  Total slices: 210\n",
      "  Slices with mandible: 51\n",
      "  Mandible pixel ratio: 0.0336%\n",
      "  Variance range: 0.000000 - 0.002903\n",
      "\n",
      "Case 33:\n",
      "  Total slices: 209\n",
      "  Slices with mandible: 42\n",
      "  Mandible pixel ratio: 0.0379%\n",
      "  Variance range: 0.000000 - 0.004833\n",
      "\n",
      "Case 34:\n",
      "  Total slices: 200\n",
      "  Slices with mandible: 42\n",
      "  Mandible pixel ratio: 0.0392%\n",
      "  Variance range: 0.000000 - 0.004596\n",
      "\n",
      "Case 35:\n",
      "  Total slices: 206\n",
      "  Slices with mandible: 46\n",
      "  Mandible pixel ratio: 0.0543%\n",
      "  Variance range: 0.000000 - 0.006032\n",
      "\n",
      "Case 36:\n",
      "  Total slices: 189\n",
      "  Slices with mandible: 34\n",
      "  Mandible pixel ratio: 0.0382%\n",
      "  Variance range: 0.000000 - 0.005052\n",
      "\n",
      "Case 37:\n",
      "  Total slices: 186\n",
      "  Slices with mandible: 44\n",
      "  Mandible pixel ratio: 0.0460%\n",
      "  Variance range: 0.000000 - 0.005065\n",
      "\n",
      "Case 38:\n",
      "  Total slices: 204\n",
      "  Slices with mandible: 42\n",
      "  Mandible pixel ratio: 0.0541%\n",
      "  Variance range: 0.000000 - 0.006632\n",
      "\n",
      "Case 39:\n",
      "  Total slices: 202\n",
      "  Slices with mandible: 38\n",
      "  Mandible pixel ratio: 0.0388%\n",
      "  Variance range: 0.000000 - 0.005827\n",
      "\n",
      "Case 40:\n",
      "  Total slices: 189\n",
      "  Slices with mandible: 38\n",
      "  Mandible pixel ratio: 0.0468%\n",
      "  Variance range: 0.000000 - 0.005808\n",
      "\n",
      "Case 41:\n",
      "  Total slices: 197\n",
      "  Slices with mandible: 32\n",
      "  Mandible pixel ratio: 0.0515%\n",
      "  Variance range: 0.000000 - 0.007225\n",
      "\n",
      "Case 42:\n",
      "  Total slices: 205\n",
      "  Slices with mandible: 43\n",
      "  Mandible pixel ratio: 0.0428%\n",
      "  Variance range: 0.000000 - 0.004874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what you're actually working with\n",
    "for i in range(1, 43):\n",
    "    case_num = f\"{i:02d}\"\n",
    "    filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_OAR_Bone_Mandible.seg.nrrd\"\n",
    "    gt = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "    gt = sitk.GetArrayFromImage(gt).astype(np.float32)\n",
    "    \n",
    "    total_slices = gt.shape[0]\n",
    "    slices_with_mandible = np.sum(np.sum(gt, axis=(1,2)) > 0)\n",
    "    total_mandible_pixels = np.sum(gt)\n",
    "    \n",
    "    print(f\"Case {case_num}:\")\n",
    "    print(f\"  Total slices: {total_slices}\")\n",
    "    print(f\"  Slices with mandible: {slices_with_mandible}\")\n",
    "    print(f\"  Mandible pixel ratio: {total_mandible_pixels / gt.size * 100:.4f}%\")\n",
    "    print(f\"  Variance range: {np.var(gt, axis=(1,2)).min():.6f} - {np.var(gt, axis=(1,2)).max():.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1018566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_RESIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc0a7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img_path, mean, std, output):\n",
    "    for i in range(len(img_path)):\n",
    "        img = sitk.ReadImage(img_path[i], sitk.sitkFloat32)\n",
    "        img = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "\n",
    "        normalized = (img - mean) / std\n",
    "        normalized = sitk.GetImageFromArray(normalized)\n",
    "\n",
    "        output_path = output + f\"{i}.nrrd\"\n",
    "        sitk.WriteImage(normalized, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a34f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNormal(img_path):\n",
    "    img_sum = 0.0\n",
    "    img_sq_sum = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for path in img_path:\n",
    "        img = sitk.ReadImage(path, sitk.sitkFloat32)\n",
    "        img = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "        img_sum += np.sum(img)\n",
    "        img_sq_sum += np.sum(img ** 2)\n",
    "        total += img.size\n",
    "\n",
    "    train_mean = img_sum/total\n",
    "    train_std = np.sqrt(img_sq_sum/total - (train_mean**2))\n",
    "\n",
    "    return train_mean, train_std       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f439c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(mri_path, ct_path, mask_path):\n",
    "    mri_path = mri_path.numpy().decode(\"utf-8\")\n",
    "    ct_path = ct_path.numpy().decode(\"utf-8\")\n",
    "    mask_path = mask_path.numpy().decode(\"utf-8\")\n",
    "\n",
    "    mri = sitk.ReadImage(mri_path, sitk.sitkFloat32)\n",
    "    ct = sitk.ReadImage(ct_path, sitk.sitkFloat32)\n",
    "    gt = sitk.ReadImage(mask_path, sitk.sitkFloat32)\n",
    "\n",
    "    slices_mri = sitk.GetArrayFromImage(mri).astype(np.float32)\n",
    "    slices_ct = sitk.GetArrayFromImage(ct).astype(np.float32)\n",
    "    slices_gt = sitk.GetArrayFromImage(gt).astype(np.float32)\n",
    "\n",
    "    slices_mri_resize = np.expand_dims(slices_mri, axis=-1)\n",
    "    slices_ct_resize = np.expand_dims(slices_ct, axis=-1)\n",
    "    slices_gt_resize = np.expand_dims(slices_gt, axis=-1)\n",
    "\n",
    "    slices_mri_resize = tf.image.resize(slices_mri_resize, [IMAGE_RESIZE, IMAGE_RESIZE], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    slices_ct_resize = tf.image.resize(slices_ct_resize, [IMAGE_RESIZE, IMAGE_RESIZE], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    slices_gt_resize = tf.image.resize(slices_gt_resize, [IMAGE_RESIZE, IMAGE_RESIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    slices = np.concatenate([slices_mri_resize, slices_ct_resize], axis=-1)\n",
    "\n",
    "    return slices, slices_gt_resize\n",
    "\n",
    "def lammy_func(mri_path, ct_path, mask_path):\n",
    "    img, mask = tf.py_function(\n",
    "        func=load_images,\n",
    "        inp=[mri_path, ct_path, mask_path],\n",
    "        Tout=[tf.float32, tf.float32]\n",
    "    )\n",
    "    img.set_shape([None, IMAGE_RESIZE, IMAGE_RESIZE, 2])\n",
    "    mask.set_shape([None, IMAGE_RESIZE, IMAGE_RESIZE, 1])\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca6a1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_path = []\n",
    "ct_path = []\n",
    "gt_path = []\n",
    "\n",
    "# mri_train_mean, mri_train_sd, ct_train_mean, ct_train_sd = normalize()\n",
    "\n",
    "for i in range(1, 43):\n",
    "    case_num = f\"{i:02d}\"\n",
    "    filepath_mri = f\"../HaN-Seg Pruned/MRI/MRI_Case_{case_num}.nrrd\"\n",
    "    mri_path.append(filepath_mri)\n",
    "    filepath_ct = f\"../HaN-Seg Pruned/CT/CT_Case_{case_num}.nrrd\"\n",
    "    ct_path.append(filepath_ct)\n",
    "    filepath_gt = f\"../HaN-Seg Pruned/GT/GT_Case_{case_num}.nrrd\"\n",
    "    gt_path.append(filepath_gt)\n",
    "\n",
    "mri_train, mri_test, ct_train, ct_test, gt_train, gt_test = train_test_split(mri_path, ct_path, gt_path, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "#################################################\n",
    "# Use only first 5-10 cases for quick experiments\n",
    "mri_train = mri_train[:10]\n",
    "ct_train = ct_train[:10]\n",
    "gt_train = gt_train[:10]\n",
    "#################################################\n",
    "\n",
    "mri_mean, mri_std = computeNormal(mri_train)\n",
    "ct_mean, ct_std = computeNormal(ct_train)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((mri_train, ct_train, gt_train))\n",
    "\n",
    "normalize(mri_train, mri_mean, mri_std, \"../HaN-Seg Pruned/Train/MRI/\")\n",
    "normalize(ct_train, ct_mean, ct_std, \"../HaN-Seg Pruned/Train/CT/\")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset\n",
    "    .map(lammy_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .unbatch()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "normalize(mri_test, mri_mean, mri_std, \"../HaN-Seg Pruned/Test/MRI/\")\n",
    "normalize(ct_test, ct_mean, ct_std, \"../HaN-Seg Pruned/Test/CT/\")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((mri_test, ct_test, gt_test))\n",
    "\n",
    "test_dataset = (\n",
    "    test_dataset\n",
    "    .map(lammy_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .unbatch()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9722ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A single Encoding step in the Contracting path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (n/2 x n/2) with num_channels feature channels\n",
    "def encode_block(inputs, num_channels):\n",
    "    # Extract num_channels feature channels from image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    skip = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Downsample each channels feature map by a factor of 2\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(skip)\n",
    "\n",
    "    return skip, x\n",
    "\n",
    "## A single Decoding step in the Expanding path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       skip_connection: tensor of corresponding encoding block\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (2nx2n) with num_channels feature channels\n",
    "def decode_block(inputs, skip_connection, num_channels):\n",
    "    # Upsample image by doubling feature space while changing feature channels to num_channels\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_channels, (2,2), strides=2, padding='same')(inputs)\n",
    "\n",
    "    # Concatenate the skip_channel and the upsampled image (doubles the feature channels)\n",
    "    # Might need to resize skip_connection, but should be fine b/c same padding in encoding\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Merge feature channels from the skip_connection and upsampled input image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Metrics\n",
    "# Source: https://medium.com/mastering-data-science/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    epsilon = 1e-6\n",
    "    # threshold = 0.9\n",
    "    # y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return (2*tp+epsilon)/(2*tp + fp + fn+epsilon)\n",
    "\n",
    "def rand_index(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    return (tp + tn) / (tp + tn + fn + fp)\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_negatives = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    possible_negatives = tf.reduce_sum(tf.cast(1 - y_true, tf.float32))\n",
    "    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5077756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    dice_weight = 10.0\n",
    "    bce_weight = 1.0\n",
    "    bce = tf.keras.losses.BinaryFocalCrossentropy(alpha=0.9)\n",
    "    loss_dice = 1.0 - dice_coeff(y_true, y_pred)\n",
    "    loss_bce = bce(y_true, y_pred)\n",
    "    loss = dice_weight * loss_dice + bce_weight * loss_bce\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2da3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(IMAGE_RESIZE, IMAGE_RESIZE, 2))\n",
    "\n",
    "# Do 5 calls of encode_block to end up with a 32x32x512 tensor\n",
    "s1, e1 = encode_block(input, 32)\n",
    "s2, e2 = encode_block(e1, 64)\n",
    "s3, e3 = encode_block(e2, 128)\n",
    "s4, e4 = encode_block(e3, 256)\n",
    "# s5, e5 = encode_block(e4, 512)\n",
    "\n",
    "# Bottleneck\n",
    "# b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(e5)\n",
    "# b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "# b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(b1)\n",
    "# b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "\n",
    "b1 = tf.keras.layers.Conv2D(512, 3, padding='same')(e4)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "b1 = tf.keras.layers.Conv2D(512, 3, padding='same')(b1)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "\n",
    "# Do 5 calls of decode_block\n",
    "# d1 = decode_block(b1, s5, 512)\n",
    "d2 = decode_block(b1, s4, 256)\n",
    "d3 = decode_block(d2, s3, 128)\n",
    "d4 = decode_block(d3, s2, 64)\n",
    "d5 = decode_block(d4, s1, 32)\n",
    "\n",
    "# Play around with activation\n",
    "output = tf.keras.layers.Conv2D(1, 1, padding='same', activation='sigmoid')(d5)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input, outputs=output, name='U-Net')\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=custom_loss,\n",
    "    metrics=['accuracy', dice_coeff, specificity, rand_index, jaccard_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d22e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9268 - dice_coeff: 0.0092 - jaccard_index: 0.6206 - loss: 9.9916 - rand_index: 0.0046 - specificity: 0.6202 - val_accuracy: 0.9946 - val_dice_coeff: 2.3035e-10 - val_jaccard_index: 0.9448 - val_loss: 12.7854 - val_rand_index: 0.0000e+00 - val_specificity: 0.9470\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9870 - dice_coeff: 0.0167 - jaccard_index: 0.7580 - loss: 9.8473 - rand_index: 0.0084 - specificity: 0.7577 - val_accuracy: 0.9971 - val_dice_coeff: 4.0234e-10 - val_jaccard_index: 0.9469 - val_loss: 11.0747 - val_rand_index: 0.0000e+00 - val_specificity: 0.9491\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9913 - dice_coeff: 0.0254 - jaccard_index: 0.8244 - loss: 9.7464 - rand_index: 0.0129 - specificity: 0.8242 - val_accuracy: 0.9960 - val_dice_coeff: 1.2032e-10 - val_jaccard_index: 0.9408 - val_loss: 10.1574 - val_rand_index: 8.9335e-15 - val_specificity: 0.9431\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9928 - dice_coeff: 0.0403 - jaccard_index: 0.8745 - loss: 9.5855 - rand_index: 0.0207 - specificity: 0.8744 - val_accuracy: 0.9888 - val_dice_coeff: 8.0558e-04 - val_jaccard_index: 0.7644 - val_loss: 10.0534 - val_rand_index: 4.0303e-04 - val_specificity: 0.7661\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9945 - dice_coeff: 0.0651 - jaccard_index: 0.9077 - loss: 9.3179 - rand_index: 0.0340 - specificity: 0.9077 - val_accuracy: 0.9955 - val_dice_coeff: 2.5462e-04 - val_jaccard_index: 0.9309 - val_loss: 10.0504 - val_rand_index: 1.2733e-04 - val_specificity: 0.9331\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9928 - dice_coeff: 0.0952 - jaccard_index: 0.9250 - loss: 8.9997 - rand_index: 0.0509 - specificity: 0.9251 - val_accuracy: 0.9976 - val_dice_coeff: 5.3446e-10 - val_jaccard_index: 0.9474 - val_loss: 11.7667 - val_rand_index: 4.9637e-32 - val_specificity: 0.9497\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9966 - dice_coeff: 0.1703 - jaccard_index: 0.9411 - loss: 8.1725 - rand_index: 0.0962 - specificity: 0.9412 - val_accuracy: 0.9975 - val_dice_coeff: 0.0040 - val_jaccard_index: 0.9351 - val_loss: 10.2152 - val_rand_index: 0.0020 - val_specificity: 0.9373\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9977 - dice_coeff: 0.2872 - jaccard_index: 0.9490 - loss: 6.9285 - rand_index: 0.1757 - specificity: 0.9491 - val_accuracy: 0.9976 - val_dice_coeff: 4.1309e-04 - val_jaccard_index: 0.9446 - val_loss: 10.1177 - val_rand_index: 2.0661e-04 - val_specificity: 0.9469\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9980 - dice_coeff: 0.3937 - jaccard_index: 0.9523 - loss: 5.7832 - rand_index: 0.2603 - specificity: 0.9526 - val_accuracy: 0.9976 - val_dice_coeff: 3.2826e-07 - val_jaccard_index: 0.9474 - val_loss: 10.2814 - val_rand_index: 1.6386e-07 - val_specificity: 0.9497\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9985 - dice_coeff: 0.4931 - jaccard_index: 0.9539 - loss: 4.7153 - rand_index: 0.3495 - specificity: 0.9542 - val_accuracy: 0.9976 - val_dice_coeff: 0.0130 - val_jaccard_index: 0.9468 - val_loss: 10.1717 - val_rand_index: 0.0067 - val_specificity: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x213ccfd9a00>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH = 10\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset,\n",
    "    epochs = EPOCH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de401438",
   "metadata": {},
   "source": [
    "# STUFF BELOW FROM AI FOR TESTING DO NOT KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bc7c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking model predictions...\n",
      "Slice 0: GT=105 pixels | Pred mean=0.001328 | Pred max=0.732827 | Pred>0.5=2\n",
      "Slice 1: GT=295 pixels | Pred mean=0.001283 | Pred max=0.152752 | Pred>0.5=0\n",
      "Slice 2: GT=410 pixels | Pred mean=0.001320 | Pred max=0.775415 | Pred>0.5=3\n",
      "Slice 3: GT=453 pixels | Pred mean=0.001275 | Pred max=0.268983 | Pred>0.5=0\n",
      "Slice 4: GT=459 pixels | Pred mean=0.001249 | Pred max=0.073918 | Pred>0.5=0\n",
      "Slice 5: GT=450 pixels | Pred mean=0.001240 | Pred max=0.144696 | Pred>0.5=0\n",
      "Slice 6: GT=426 pixels | Pred mean=0.001232 | Pred max=0.020290 | Pred>0.5=0\n",
      "Slice 7: GT=368 pixels | Pred mean=0.001230 | Pred max=0.005894 | Pred>0.5=0\n",
      "\n",
      "Slice 0: GT=47 pixels | Pred mean=0.001232 | Pred max=0.012042 | Pred>0.5=0\n",
      "Slice 1: GT=35 pixels | Pred mean=0.001232 | Pred max=0.121998 | Pred>0.5=0\n",
      "Slice 2: GT=17 pixels | Pred mean=0.001227 | Pred max=0.064439 | Pred>0.5=0\n",
      "Slice 3: GT=12 pixels | Pred mean=0.001225 | Pred max=0.189278 | Pred>0.5=0\n",
      "Slice 4: GT=9 pixels | Pred mean=0.001219 | Pred max=0.371471 | Pred>0.5=0\n",
      "Slice 5: GT=22 pixels | Pred mean=0.001878 | Pred max=1.000000 | Pred>0.5=39\n",
      "Slice 6: GT=42 pixels | Pred mean=0.001937 | Pred max=1.000000 | Pred>0.5=41\n",
      "Slice 7: GT=55 pixels | Pred mean=0.002007 | Pred max=1.000000 | Pred>0.5=45\n",
      "\n",
      "Slice 0: GT=188 pixels | Pred mean=0.001420 | Pred max=0.995908 | Pred>0.5=6\n",
      "Slice 1: GT=211 pixels | Pred mean=0.001424 | Pred max=0.998466 | Pred>0.5=7\n",
      "Slice 2: GT=222 pixels | Pred mean=0.001404 | Pred max=0.997976 | Pred>0.5=8\n",
      "Slice 3: GT=229 pixels | Pred mean=0.001341 | Pred max=0.851918 | Pred>0.5=2\n",
      "Slice 4: GT=227 pixels | Pred mean=0.001307 | Pred max=0.014275 | Pred>0.5=0\n",
      "Slice 5: GT=162 pixels | Pred mean=0.001307 | Pred max=0.025201 | Pred>0.5=0\n",
      "Slice 6: GT=151 pixels | Pred mean=0.001314 | Pred max=0.272768 | Pred>0.5=0\n",
      "Slice 7: GT=118 pixels | Pred mean=0.001353 | Pred max=0.722467 | Pred>0.5=2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking model predictions...\")\n",
    "for img, mask in train_dataset.take(3):\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    \n",
    "    for i in range(min(8, img.shape[0])):\n",
    "        mask_sum = tf.reduce_sum(mask[i]).numpy()\n",
    "        pred_mean = np.mean(pred[i])\n",
    "        pred_max = np.max(pred[i])\n",
    "        pred_sum_thresholded = np.sum(pred[i] > 0.5)\n",
    "        \n",
    "        print(f\"Slice {i}: GT={mask_sum:.0f} pixels | \"\n",
    "              f\"Pred mean={pred_mean:.6f} | \"\n",
    "              f\"Pred max={pred_max:.6f} | \"\n",
    "              f\"Pred>0.5={pred_sum_thresholded:.0f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dacb4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5: Dice = 0.45445767045021057\n",
      "Threshold 0.6: Dice = 0.4636862277984619\n",
      "Threshold 0.7: Dice = 0.4714776575565338\n",
      "Threshold 0.8: Dice = 0.48029953241348267\n",
      "Threshold 0.9: Dice = 0.49106302857398987\n"
     ]
    }
   ],
   "source": [
    "# Test different thresholds\n",
    "for threshold in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    pred_thresholded = (pred > threshold).astype(float)\n",
    "    dice = dice_coeff(mask, pred_thresholded)\n",
    "    print(f\"Threshold {threshold}: Dice = {dice}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
