{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f0d33e",
   "metadata": {},
   "source": [
    "Preprocessing Images - Can Convert into .py file later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3999b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS ONCE\n",
    "pip install pynrrd\n",
    "pip install opencv-python\n",
    "pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87027ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data from the HaN-Seg dataset\n",
    "# below lists follow indexing: list[case_num-1][0] for data, list[case_num-1][1] for metadata\n",
    "\n",
    "def openFiles():\n",
    "    nrrd_ct_data = [] #1024x1024 images with varying depth\n",
    "    nrrd_mri_data = [] #512x512 images with varying depth\n",
    "    nrrd_segment_data = [] #1024x1024 images with varying depth\n",
    "\n",
    "    for i in range(1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_CT.nrrd\"\n",
    "        data = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        nrrd_ct_data.append(data)\n",
    "\n",
    "    for i in range (1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_IMG_MR_T1.nrrd\"\n",
    "        data = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        nrrd_mri_data.append(data)\n",
    "\n",
    "\n",
    "    for i in range (1, 43):\n",
    "        case_num = f\"{i:02d}\"\n",
    "        filepath = f\"../HaN-Seg/set_1/case_{case_num}/case_{case_num}_OAR_Bone_Mandible.seg.nrrd\"\n",
    "        data = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "        nrrd_segment_data.append(data)\n",
    "    return nrrd_ct_data, nrrd_mri_data, nrrd_segment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrrd_ct_data, nrrd_mri_data, nrrd_segment_data = openFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf436b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nrrd_ct_data))\n",
    "print(type(nrrd_ct_data[0]))\n",
    "ct_arr = sitk.GetArrayFromImage(nrrd_ct_data[0])\n",
    "plt.imshow(ct_arr[105, :, :], cmap='gray')\n",
    "print(nrrd_ct_data[0].GetSize())\n",
    "print(nrrd_ct_data[0].GetSpacing())\n",
    "\n",
    "print(len(nrrd_mri_data))\n",
    "mri_arr = sitk.GetArrayFromImage(nrrd_mri_data[0])\n",
    "mri = nrrd_mri_data[0]\n",
    "plt.imshow(mri_arr[53, :, :], cmap='gray')\n",
    "print(nrrd_mri_data[0].GetSize())\n",
    "print(nrrd_mri_data[0].GetSpacing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456bdb7c",
   "metadata": {},
   "source": [
    "ALL CODE BELOW IS FROM THE SIMPLEITK TUTORIAL\n",
    "https://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/60_Registration_Introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# Callback invoked by the IPython interact method for scrolling through image stacks of\n",
    "# the two images being registered.\n",
    "def display_images(fixed_image_z, moving_image_z, fixed_npa, moving_npa):\n",
    "    # Create a figure with two subplots and the specified size.\n",
    "    plt.subplots(1, 2, figsize=(10, 8))\n",
    "\n",
    "    # Draw the fixed image in the first subplot.\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(fixed_npa[fixed_image_z, :, :], cmap=plt.cm.Greys_r)\n",
    "    plt.title(\"fixed image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Draw the moving image in the second subplot.\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(moving_npa[moving_image_z, :, :], cmap=plt.cm.Greys_r)\n",
    "    plt.title(\"moving image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Callback invoked by the IPython interact method for scrolling and modifying the alpha blending\n",
    "# of an image stack of two images that occupy the same physical space.\n",
    "def display_images_with_alpha(image_z, alpha, fixed, moving):\n",
    "    img = (1.0 - alpha) * fixed[:, :, image_z] + alpha * moving[:, :, image_z]\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(img), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Callback invoked when the StartEvent happens, sets up our new data.\n",
    "def start_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    metric_values = []\n",
    "    multires_iterations = []\n",
    "\n",
    "\n",
    "# Callback invoked when the EndEvent happens, do cleanup of data and figure.\n",
    "def end_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    del metric_values\n",
    "    del multires_iterations\n",
    "    # Close figure, we don't want to get a duplicate of the plot latter on.\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Callback invoked when the IterationEvent happens, update our data and display new figure.\n",
    "def plot_values(registration_method):\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    metric_values.append(registration_method.GetMetricValue())\n",
    "    # Clear the output area (wait=True, to reduce flickering), and plot current data\n",
    "    clear_output(wait=True)\n",
    "    # Plot the similarity metric values\n",
    "    plt.plot(metric_values, \"r\")\n",
    "    plt.plot(\n",
    "        multires_iterations,\n",
    "        [metric_values[index] for index in multires_iterations],\n",
    "        \"b*\",\n",
    "    )\n",
    "    plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "    plt.ylabel(\"Metric Value\", fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the\n",
    "# metric_values list.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64723a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initial translation: {initial_transform.GetTranslation()}\")\n",
    "print(f\"Are these images from the same patient/session? Do they roughly cover the same anatomy?\")\n",
    "\n",
    "# Check if images even overlap in physical space\n",
    "print(f\"\\nFixed image physical bounds:\")\n",
    "print(f\"  Origin: {fixed_image.GetOrigin()}\")\n",
    "print(f\"  Max: {[o + s*sz for o,s,sz in zip(fixed_image.GetOrigin(), fixed_image.GetSpacing(), fixed_image.GetSize())]}\")\n",
    "\n",
    "print(f\"\\nMoving image physical bounds:\")\n",
    "print(f\"  Origin: {moving_image.GetOrigin()}\")\n",
    "print(f\"  Max: {[o + s*sz for o,s,sz in zip(moving_image.GetOrigin(), moving_image.GetSpacing(), moving_image.GetSize())]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registration Testing\n",
    "ct = nrrd_ct_data[0]\n",
    "mri = nrrd_mri_data[0]\n",
    "\n",
    "fixed_image = ct\n",
    "moving_image = mri\n",
    "\n",
    "initial_transform = sitk.CenteredTransformInitializer(\n",
    "    fixed_image,\n",
    "    moving_image,\n",
    "    sitk.Euler3DTransform(),\n",
    "    sitk.CenteredTransformInitializerFilter.GEOMETRY,\n",
    ")\n",
    "\n",
    "min_value = float(sitk.GetArrayViewFromImage(moving_image).min())\n",
    "moving_resampled = sitk.Resample(\n",
    "    moving_image,\n",
    "    fixed_image,\n",
    "    initial_transform,\n",
    "    sitk.sitkLinear,\n",
    "    min_value,\n",
    "    moving_image.GetPixelID(),\n",
    ")\n",
    "\n",
    "interact(\n",
    "    display_images_with_alpha,\n",
    "    image_z=(0, fixed_image.GetSize()[2] - 1),\n",
    "    alpha=(0.0, 1.0, 0.05),\n",
    "    fixed=fixed(fixed_image),\n",
    "    moving=fixed(moving_resampled),\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "# Similarity metric settings.\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "# Optimizer settings.\n",
    "registration_method.SetOptimizerAsGradientDescent(\n",
    "    learningRate=1.0,\n",
    "    numberOfIterations=100,\n",
    "    convergenceMinimumValue=1e-6,\n",
    "    convergenceWindowSize=10,\n",
    ")\n",
    "registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "# Setup for the multi-resolution framework.\n",
    "registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "# Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "# # Connect all of the observers so that we can perform plotting during registration.\n",
    "# registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "# registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "# registration_method.AddCommand(\n",
    "#     sitk.sitkMultiResolutionIterationEvent, update_multires_iterations\n",
    "# )\n",
    "# registration_method.AddCommand(\n",
    "#     sitk.sitkIterationEvent, lambda: plot_values(registration_method)\n",
    "# )\n",
    "\n",
    "final_transform = registration_method.Execute(\n",
    "    sitk.Cast(fixed_image, sitk.sitkFloat32), sitk.Cast(moving_image, sitk.sitkFloat32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final metric value: {registration_method.GetMetricValue()}\")\n",
    "print(\n",
    "    f\"Optimizer's stopping condition, {registration_method.GetOptimizerStopConditionDescription()}\"\n",
    ")\n",
    "\n",
    "moving_resampled = sitk.Resample(\n",
    "    moving_image,\n",
    "    fixed_image,\n",
    "    final_transform,\n",
    "    sitk.sitkLinear,\n",
    "    min_value,\n",
    "    moving_image.GetPixelID(),\n",
    ")\n",
    "\n",
    "interact(\n",
    "    display_images_with_alpha,\n",
    "    image_z=(0, fixed_image.GetSize()[2] - 1),\n",
    "    alpha=(0.0, 1.0, 0.05),\n",
    "    fixed=fixed(fixed_image),\n",
    "    moving=fixed(moving_resampled),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcdcdf",
   "metadata": {},
   "source": [
    "From lab b pt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = nrrd_ct_data[0]\n",
    "mri = nrrd_mri_data[0]\n",
    "\n",
    "img_mri = ct\n",
    "moving_img = mri\n",
    "min_value = float(sitk.GetArrayViewFromImage(moving_img).min())\n",
    "\n",
    "init_tx = sitk.CenteredTransformInitializer(\n",
    "    img_mri, moving_img,\n",
    "    sitk.Euler3DTransform(),\n",
    "    sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    ")\n",
    "\n",
    "# ---- Configure registration (Mattes MI + multi-resolution) ----\n",
    "R = sitk.ImageRegistrationMethod()\n",
    "R.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "R.SetMetricSamplingStrategy(R.RANDOM)\n",
    "R.SetMetricSamplingPercentage(0.01)\n",
    "R.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "R.SetOptimizerAsRegularStepGradientDescent(\n",
    "    learningRate=1.0, minStep=1e-4, numberOfIterations=500, relaxationFactor=0.5\n",
    ")\n",
    "R.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "R.SetShrinkFactorsPerLevel([4, 2, 1])\n",
    "R.SetSmoothingSigmasPerLevel([2.0, 1.0, 0.0])\n",
    "R.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "R.SetInitialTransform(init_tx, inPlace=False)\n",
    "\n",
    "final_tx = R.Execute(img_mri, moving_img)\n",
    "\n",
    "ct_rigid = sitk.Resample(\n",
    "    moving_img,  # CT (moving)\n",
    "    img_mri,     # MRI (fixed)\n",
    "    final_tx,\n",
    "    sitk.sitkLinear, min_value,\n",
    "    moving_img.GetPixelIDValue()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40679af",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    display_images_with_alpha,\n",
    "    image_z=(0, img_mri.GetSize()[2] - 1),\n",
    "    alpha=(0.0, 1.0, 0.05),\n",
    "    fixed=fixed(img_mri),\n",
    "    moving=fixed(ct_rigid),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12344d12",
   "metadata": {},
   "source": [
    "Testing U-net CNN pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83891e1",
   "metadata": {},
   "source": [
    "DO TRAIN_TEST_SPLIT HERE:\n",
    "    - FOR EACH TRAINING POINT, INCREMENTALLY CALCULATE MEAN AND SD\n",
    "    - USE A 2ND PASS TO NORMALIZE THE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image\n",
    "\n",
    "mri_image_reg = sitk.GetArrayViewFromImage(moving_resampled).astype(np.float32)\n",
    "ground_truth = sitk.GetArrayFromImage(nrrd_segment_data[0]).astype(np.float32)\n",
    "\n",
    "i = 100\n",
    "plt.imshow(mri_image_reg[i])\n",
    "print(mri_image_reg[i])\n",
    "\n",
    "img_sum = 0.0\n",
    "img_sq_sum = 0.0\n",
    "total = 0\n",
    "\n",
    "img_sum += np.sum(mri_image_reg)\n",
    "img_sq_sum += np.sum(mri_image_reg ** 2)\n",
    "total += mri_image_reg.size\n",
    "\n",
    "train_mean = img_sum/total\n",
    "\n",
    "# Leverage fact that Var(X) = E(X^2) - E(X)^2 where E(X) is the mean\n",
    "train_sd = np.sqrt(img_sq_sum/total - (train_mean**2))\n",
    "\n",
    "mri_image_reg = (mri_image_reg - train_mean) / train_sd\n",
    "\n",
    "# save to a new file & list = mri_reg_list\n",
    "plt.imshow(mri_image_reg[i])\n",
    "print(np.var(mri_image_reg[i])< 1e-14)\n",
    "print(mri_image_reg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b67f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Slices\n",
    "# for img, seg_mask in nmri_reg_list, nrrd_segment_data\n",
    "slices = []\n",
    "slices_gt = []\n",
    "\n",
    "# Need for loop for a list of volumes\n",
    "slice_var = np.var(ground_truth, axis = (1, 2))\n",
    "mask = slice_var > 1e-10\n",
    "slices = mri_image_reg[mask]\n",
    "slices_gt = ground_truth[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410db957",
   "metadata": {},
   "source": [
    "### Preparing Data for Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96377f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_RESIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38191989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "slice_arr = np.array(slices)\n",
    "slices_gt_arr = np.array(slices_gt)\n",
    "print(np.shape(slice_arr))\n",
    "\n",
    "slices_resize = np.expand_dims(slice_arr, axis=-1)\n",
    "slices_gt_resize = np.expand_dims(slices_gt_arr, axis=-1)\n",
    "\n",
    "slices_resize = tf.image.resize(slices_resize, (IMAGE_RESIZE, IMAGE_RESIZE)).numpy()\n",
    "slices_gt_resize = tf.image.resize(slices_gt_resize, (IMAGE_RESIZE, IMAGE_RESIZE)).numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(slices_resize, slices_gt_resize, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# X_train = np.expand_dims(X_train, axis=-1)\n",
    "# y_train = np.expand_dims(y_train, axis=-1)\n",
    "\n",
    "# X_test = np.expand_dims(X_test, axis=-1)\n",
    "# y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True, zoom_range=0.2)\n",
    "mask_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "image_generator = mri_datagen.flow(\n",
    "    X_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed = RANDOM_SEED\n",
    ")\n",
    "\n",
    "mask_generator = mask_datagen.flow(\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed = RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "test_image_generator = test_datagen.flow(\n",
    "    X_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    seed = RANDOM_SEED\n",
    ")\n",
    "\n",
    "test_mask_generator = mask_datagen.flow(\n",
    "    y_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    seed = RANDOM_SEED\n",
    ")\n",
    "\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bfbca",
   "metadata": {},
   "source": [
    "### U-Net CNN Model\n",
    "Sources:\n",
    "\n",
    "References for Code:\n",
    "\n",
    "https://www.geeksforgeeks.org/machine-learning/u-net-architecture-explained/\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/unet-architecture-image-segmentation\n",
    "\n",
    "General References:\n",
    "\n",
    "https://medium.com/@alejandro.itoaramendia/decoding-the-u-net-a-complete-guide-810b1c6d56d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b93cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A single Encoding step in the Contracting path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (n/2 x n/2) with num_channels feature channels\n",
    "def encode_block(inputs, num_channels):\n",
    "    # Extract num_channels feature channels from image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    skip = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Downsample each channels feature map by a factor of 2\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(skip)\n",
    "\n",
    "    return skip, x\n",
    "\n",
    "## A single Decoding step in the Expanding path of a U-Net CNN\n",
    "## @Inputs:\n",
    "##       inputs: image of size (nxn) with k feature channels\n",
    "##       skip_connection: tensor of corresponding encoding block\n",
    "##       num_channels: number of channels to have in output image (i.e. depth of output tensor)\n",
    "## @Outputs: \n",
    "##       x: image of size (2nx2n) with num_channels feature channels\n",
    "def decode_block(inputs, skip_connection, num_channels):\n",
    "    # Upsample image by doubling feature space while changing feature channels to num_channels\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_channels, (2,2), strides=2, padding='same')(inputs)\n",
    "\n",
    "    # Concatonate the skip_channel and the upsampled image (doubles the feature channels)\n",
    "    # Might need to resize skip_connection, but should be fine b/c same padding in encoding\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Merge feature channels from the skip_connection and upsampled input image\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(num_channels, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d746d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "# Source: https://medium.com/mastering-data-science/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return (2*tp)/(2*tp + fp + fn)\n",
    "\n",
    "def rand_index(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "    tn = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    return (tp + tn) / (tp + tn + fn + fp)\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_negatives = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))\n",
    "    possible_negatives = tf.reduce_sum(tf.cast(1 - y_true, tf.float32))\n",
    "    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(IMAGE_RESIZE, IMAGE_RESIZE, 1))\n",
    "\n",
    "# Do 5 calls of encode_block to end up with a 32x32x512 tensor\n",
    "s1, e1 = encode_block(input, 32)\n",
    "s2, e2 = encode_block(e1, 64)\n",
    "s3, e3 = encode_block(e2, 128)\n",
    "s4, e4 = encode_block(e3, 256)\n",
    "s5, e5 = encode_block(e4, 512)\n",
    "\n",
    "# Bottleneck\n",
    "b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(e5)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "b1 = tf.keras.layers.Conv2D(1024, 3, padding='same')(b1)\n",
    "b1 = tf.keras.layers.Activation('relu')(b1)\n",
    "\n",
    "# Do 5 calls of decode_block\n",
    "d1 = decode_block(b1, s5, 512)\n",
    "d2 = decode_block(d1, s4, 256)\n",
    "d3 = decode_block(d2, s3, 128)\n",
    "d4 = decode_block(d3, s2, 64)\n",
    "d5 = decode_block(d4, s1, 32)\n",
    "\n",
    "# Play around with activation\n",
    "output = tf.keras.layers.Conv2D(1, 1, padding='same', activation='sigmoid')(d5)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input, outputs=output, name='U-Net')\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss= 'binary_crossentropy',\n",
    "    metrics=['accuracy', dice_coeff, specificity, rand_index, jaccard_index]\n",
    ")\n",
    "\n",
    "#TODO Finish this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeca2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", gpus)\n",
    "\n",
    "# Check if TensorFlow is using GPU\n",
    "print(\"GPU device used by TensorFlow:\", tf.test.gpu_device_name())\n",
    "\n",
    "# Optional: Check if TensorFlow sees GPU and memory info\n",
    "for gpu in gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpu)\n",
    "    print(details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 4\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset,\n",
    "    epochs = EPOCH\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
